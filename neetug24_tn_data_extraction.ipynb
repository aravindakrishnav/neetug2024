import tqdm
import requests
from urllib.parse import urlparse
from requests.exceptions import RequestException
from concurrent.futures import ThreadPoolExecutor, as_completed

def download_pdf_from_url(url, save_path):
    try:
        # Send a GET request to the URL
        response = requests.get(url)
       
        # Check if the request was successful (status code 200)
        if response.status_code == 200:
            # Check if the content type is PDF
            if response.headers.get('content-type') == 'application/pdf':
                # Extract the filename from the URL
                parsed_url = urlparse(url)
                filename = parsed_url.path.split('/')[-1]
               
                # Save the PDF content to a file
                with open(save_path + filename, 'wb') as f:
                    f.write(response.content)
               
                #print(f"PDF downloaded successfully and saved as: {filename}")
            else:
                #print(f"Skipping URL {url}: Content type is not PDF")
                pass
        else:
            #print(f"Skipping URL {url}: Failed to download PDF. Status code: {response.status_code}")
            pass
   
    except RequestException as e:
        print(f"Skipping URL {url}: Error occurred during request: {str(e)}")

# Define a function for processing a batch of URLs
def process_batch(start, end, url_base, save_path):
    for i in range(start, end + 1):
        url = f"{url_base}{i}.pdf"
        download_pdf_from_url(url, save_path)

# Example usage:
url_base = 'https://neetfs.ntaonline.in/NEET_2024_Result/'
start_num = 410000
end_num = 414000

save_path = 'D:\\NEET UG 2024 Analysis\\Center Data PDFs\\'  # Ensure this path ends with a backslash

# Define the number of threads to use
num_threads = 10
batch_size = (end_num - start_num + 1) // num_threads

# Create a ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=num_threads) as executor:
    futures = []
    for i in range(num_threads):
        batch_start = start_num + i * batch_size
        batch_end = batch_start + batch_size - 1
        if i == num_threads - 1:
            batch_end = end_num  # Ensure the last batch goes to the end number
        futures.append(executor.submit(process_batch, batch_start, batch_end, url_base, save_path))

    # Use tqdm to display the progress
    for future in tqdm.tqdm(as_completed(futures), total=num_threads):
        future.result()  # Wait for the result, raise exceptions if any
